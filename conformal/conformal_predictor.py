from typing import Self

import mapie
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.base import BaseEstimator, ClassifierMixin
from datasets.utils import AbstractDataloader

class SKLearnWrapper(BaseEstimator, ClassifierMixin):
    """
    A Scikit-learn compatible wrapper for a CLIP-based classifier.
    
    Parameters:
        clip_model (torch.nn.Module): The CLIP model used for generating embeddings.
        model_dim (int): Dimensionality of the embeddings. Defaults to 512.
        temperature (float): Scaling factor for softmax during predictions. Defaults to 100.
    """
    def __init__(self, clip_model:torch.nn.Module, model_dim:int = 512, temperature:int = 100) -> None:
        self.clip_model = clip_model
        self.model_dim = model_dim
        self.text_embeddings = None # generated by calling the `fit()` method
        self.temperature = temperature

    def fit(self, data_loader:AbstractDataloader, embeddings:torch.Tensor = None, trained_context:str=None) -> Self:
        """
        Train the classifier by generating or using provided textual embeddings.
        
        Parameters:
            data_loader (AbstractDataloader): Child class of AbstractDataloader instance with methods to fetch text prompts and generate embeddings.
            embeddings (torch.Tensor, optional): Precomputed embeddings. If not provided, they will be generated.
            trained_context (str): Pickle filename of a CoOp training context that should be located in ./Coop/learned_contexts. No context applied if None (default).
        
        Returns:
            self: The trained classifier instance.
        """
        data_loader.get_labels_names()
        
        if embeddings is None:
            self.text_embeddings = data_loader.get_textual_prototypes(
                data_loader.get_text_prompts(),
                self.clip_model,
                model_dim=self.model_dim,
                trained_context=trained_context
            ).to(torch.float32).cpu()
        else: 
            self.text_embeddings = embeddings.to(torch.float32).cpu()
        
        # This attribute is used by MAPIE for fitting
        self.classes_ = np.arange(self.text_embeddings.shape[1])

        return self

    def predict(self, X:torch.Tensor|np.ndarray) -> np.ndarray:
        """
        Predict the majority class for the given input features.
        
        Parameters:
            X (torch.Tensor or np.ndarray): Input features.
        
        Returns:
            np.ndarray: Predicted class labels.
        
        Raises:
            RuntimeError: If method `fit()` has not been called before this method.
        """
        soft_labels = self.predict_proba(X)
        return np.argmax(soft_labels, axis=1)

    def predict_proba(self, X:torch.Tensor|np.ndarray) -> np.ndarray:
        """
        Compute class probabilities for the given input features.
        
        Parameters:
            X (torch.Tensor or np.ndarray): Input features.
        
        Returns:
            np.ndarray: Predicted class probabilities.
        
        Raises:
            RuntimeError: If method `fit()` has not been called before this method.
        """
        if self.text_embeddings is None:
            raise RuntimeError("call `fit()` method first to generate prompt embeddings")
        
        # cast the input to torch.Tensor and move it to cpu
        tensor_X = torch.from_numpy(X) if type(X) == np.ndarray else X.cpu()
        
        soft_labels = F.softmax(self.temperature * tensor_X.to(torch.float32) @ self.text_embeddings, dim = -1)
        return soft_labels.numpy()
    
def wrap_and_fit(
        model:ClassifierMixin, 
        X_calib:torch.Tensor, 
        y_calib:torch.Tensor, 
        method:str = 'lac', 
        seed:int = 1, 
        text_prototypes:torch.Tensor = None
    ) -> mapie.classification.MapieClassifier:
    """
    Wrap a SKLearn-compatible model with a MAPIE conformal predictor and fit it using calibration data.
    
    Parameters:
        model (ClassifierMixin): The pre-trained SKLearn model to be wrapped and fitted.
        X_calib (torch.Tensor): Calibration input data.
        y_calib (torch.Tensor): Calibration target labels.
        method (str): Conformity scoring method to use. Options are 'lac', 'aps', 'raps'. Defaults to 'lac'.
        seed (int, optional): Random seed for reproducibility. Defaults to 1.
        text_prototypes (torch.Tensor, optional): Precomputed textual prototypes for embeddings. If not provided, they will be generated.
    
    Returns:
        mapie.classification.MapieClassifier: A MAPIE classifier fitted with the provided calibration data.
    """
    methods = {
        'lac': mapie.conformity_scores.LACConformityScore(),
        'aps': mapie.conformity_scores.APSConformityScore(),
        'raps':mapie.conformity_scores.RAPSConformityScore()
    }

    cp = mapie.classification.MapieClassifier(
        estimator=model, 
        cv="prefit", 
        conformity_score=methods[method], 
        random_state=seed
    )
    print(type(X_calib), type(y_calib))

    cp.fit(X_calib, y_calib, embeddings = text_prototypes)
    return cp